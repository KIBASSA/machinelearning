{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoML_Kaggle:\n",
    "    def __init__(self, typeMl, file_train,file_test, target):\n",
    "        self.type_ml = typeMl\n",
    "        self.target = target\n",
    "        self.scaler = StandardScaler()\n",
    "        self.logreg = LogisticRegression()\n",
    "        self.best_estimator = None\n",
    "        self.best_score = 0\n",
    "        self.data_train = pd.read_csv(file_train)\n",
    "        self.data_test = pd.read_csv(file_test)\n",
    "        \n",
    "    def _del_nan(self, X):\n",
    "        #si les nan sont > 20%, on del\n",
    "        for col in X.columns:\n",
    "            if (X[col].isna().sum() * 100)/len(X) > 20:\n",
    "                X = X.drop(col, axis = 1)\n",
    "        return X\n",
    "    \n",
    "    def _replace_nan(self,X):\n",
    "        for col in X.columns:\n",
    "            if col in X.select_dtypes(include = [np.number]):\n",
    "                mean = np.mean(X[col])\n",
    "                X[col].fillna(mean, inplace = True)\n",
    "            else:\n",
    "                X[col].fillna(X[col].mode()[0], inplace = True)\n",
    "        return X\n",
    "    \n",
    "    def _set_get_dummies(self, X):\n",
    "        X = pd.get_dummies(X,drop_first= True)\n",
    "        return X\n",
    "    \n",
    "    def _del_unused_cols(self, X):\n",
    "        for col in  X.columns:\n",
    "            if len(X[col].unique()) == len(X):\n",
    "                X.drop(col, axis = 1)\n",
    "        return X\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        return self.scaler.fit_transform(X)\n",
    "    \n",
    "    def _get_grid_search_cls(self):\n",
    "        if self.type_ml == \"classification\":\n",
    "            return  {\"logreg\":[LogisticRegression(),[\n",
    "                {'penalty': ['l2'],'C':[0.1,0.6,1],\n",
    "                  'multi_class':['ovr', 'multinomial'],'class_weight':['balanced', None],\n",
    "                  'solver':['lbfgs','sag','newton-cg'],'max_iter':[1000],\"random_state\": [0]\n",
    "                },\n",
    "                {'penalty': ['l1','l2'],'C':[0.1,0.6,1],\n",
    "                  'multi_class':['ovr'],'class_weight':['balanced', None],\n",
    "                  'solver':['liblinear'],'max_iter':[1000],\"random_state\": [0]\n",
    "                },]],\n",
    "              \"SVM\":[SVC(),[\n",
    "                {'C': [0.1,0.6,1,2],'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['linear'],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                },\n",
    "                {'C': [0.1,0.6,1,2], 'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['rbf'],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                },\n",
    "                {'C': [0.1,0.6,1,2], 'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['poly'], 'degree': [2,3,4,5,6,7],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                },\n",
    "                {'C': [0.1,0.6,1,2,],'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['sigmoid'],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                }]],\n",
    "              \"RanFor\":[RandomForestClassifier(),{\n",
    "                   'n_estimators': [10,20],\n",
    "                   \"criterion\": [\"gini\", \"entropy\"],\n",
    "                   \"max_depth\": [8, 10, 12, None],\n",
    "                   \"min_samples_split\": [2, 5],\n",
    "                   \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "                   \"bootstrap\": [True, False],\n",
    "                   \"class_weight\": [\"balanced\", \"balanced_subsample\", None],\n",
    "                   \"random_state\": [0]\n",
    "                   }]}\n",
    "        else:\n",
    "            return  {\"linreg\":[LinearRegression(),[{'fit_intercept':[True, False]}]],\n",
    "              \"SVM\":[SVR(kernel = \"linear\"),[\n",
    "                {'C': [0.1,0.6,1,2]}]],\n",
    "              \"RanFor\":[RandomForestRegressor(),{\n",
    "                   'n_estimators': [20,30],\n",
    "                   \"max_depth\": [8, 10, 12, None],\n",
    "                   \"min_samples_split\": [2, 5],\n",
    "                   \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "                   \"bootstrap\": [True, False],\n",
    "                   \"random_state\": [0]\n",
    "                   }],\n",
    "                    \"XGBRegressor\":[XGBRegressor(),{'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "                  'objective':['reg:linear'],\n",
    "                  'learning_rate': [.03,0.04, 0.05, .07], #so called `eta` value\n",
    "                  'max_depth': [3,5, 6, 7],\n",
    "                  'min_child_weight': [3,4,5],\n",
    "                  'silent': [1],\n",
    "                  'subsample': [0.7],\n",
    "                  'colsample_bytree': [0.7],\n",
    "                  'n_estimators': [500]}]} \n",
    "    \n",
    "    def local_predict(self):\n",
    "        if self.best_estimator == None:\n",
    "            print(\"fit before predict.. \")\n",
    "        else:\n",
    "            return self.best_estimator.predict(self.data_test_trans)\n",
    "        \n",
    "    def fit(self):\n",
    "        self.y = self.data_train[self.target]\n",
    "        self.data_train.drop(self.target, axis = 1)\n",
    "        self.full_data = self.data_train.append(self.data_test).reset_index(drop=True)\n",
    "        self.full_data = self._del_unused_cols(self.full_data)\n",
    "        self.full_data = self._del_nan(self.full_data)\n",
    "        self.full_data = self._replace_nan(self.full_data)\n",
    "        self.full_data = self._set_get_dummies(self.full_data)\n",
    "        \n",
    "        self.data_train = self.full_data[self.full_data.Id.isin(self.data_train[\"Id\"].tolist())]\n",
    "        self.data_test = self.full_data[self.full_data.Id.isin(self.data_test[\"Id\"].tolist())]\n",
    "        \n",
    "        self.data_train_trans = self._transform(self.data_train)\n",
    "        \n",
    "        self.data_test_trans = self._transform(self.data_test)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.data_train_trans, self.y, test_size=0.20, random_state=42)\n",
    "        \n",
    "        models = self._get_grid_search_cls()\n",
    "        for key,classificateur in models.items():\n",
    "            estimat = classificateur[0]\n",
    "            parameters = classificateur[1]\n",
    "            clf = GridSearchCV(estimat, param_grid = parameters, return_train_score=True, cv = 5, n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "            if clf.best_score_ > self.best_score:\n",
    "                self.best_score = clf.best_score_\n",
    "                self.best_estimator = clf.best_estimator_\n",
    "                print(key,\":\",self.best_score,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kibas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "C:\\Users\\kibas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : 0.29581716825704424 %\n",
      "RanFor : 0.8373963442215155 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kibas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor : 0.8664586505372349 %\n"
     ]
    }
   ],
   "source": [
    "autoML = AutoML_Kaggle(\"regression\", \"house_pricestrain.csv\",\"house prices_test.csv\",\"SalePrice\")\n",
    "autoML.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SalePrices = autoML.local_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.07, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=5, missing=None, n_estimators=500,\n",
       "             n_jobs=1, nthread=4, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=1,\n",
       "             subsample=0.7, verbosity=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoML.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1459"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(autoML.data_test[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'SalePrice':SalePrices} \n",
    "submit = pd.DataFrame(data, index = autoML.data_test[\"Id\"])\n",
    "submit.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
