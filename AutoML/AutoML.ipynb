{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoML:\n",
    "    def __init__(self, typeMl, file, target):\n",
    "        self.type_ml = typeMl\n",
    "        self.target = target\n",
    "        self.scaler = StandardScaler()\n",
    "        self.logreg = LogisticRegression()\n",
    "        self.best_estimator = None\n",
    "        self.best_score = 0\n",
    "        self.data = pd.read_csv(file)\n",
    "    \n",
    "    def _del_unused_cols(self):\n",
    "        for col in  self.data.columns:\n",
    "            if len(self.data[col].unique()) == len(self.data):\n",
    "                self.data.drop(col, axis = 1)\n",
    "    \n",
    "    def _del_nan(self):\n",
    "        #si les nan sont > 20%, on del\n",
    "        for col in self.data.columns:\n",
    "            if (self.data[col].isna().sum() * 100)/len(self.data) > 20:\n",
    "                self.data = self.X.drop(col, axis = 1)\n",
    "    \n",
    "    def _replace_nan(self):\n",
    "        for col in self.data.columns:\n",
    "            if col in self.data.select_dtypes(include = [np.number]):\n",
    "                mean = np.mean(self.data[col])\n",
    "                self.data[col].fillna(mean, inplace = True)\n",
    "            else:\n",
    "                self.data[col].fillna(self.data[col].mode, inplace = True)\n",
    "    \n",
    "    def _set_X_y(self):\n",
    "        self.y = self.data[self.target]\n",
    "        self.X = self.data.drop(self.target, axis=1)\n",
    "    \n",
    "    def _set_get_dummies(self):\n",
    "        for col in self.X.columns:\n",
    "            if col in self.X.select_dtypes(include = [np.object]):\n",
    "                self.X = pd.concat([self.X,pd.get_dummies(self.X[col])], axis=1)\n",
    "                self.X = self.X.drop(col, axis = 1)\n",
    "                \n",
    "    def _transform(self):\n",
    "        self.X_trans = self.scaler.fit_transform(self.X)\n",
    "            \n",
    "    def pre_processing(self):\n",
    "        \n",
    "        self._del_unused_cols()\n",
    "        self._del_nan()\n",
    "        self._replace_nan()\n",
    "        self._set_X_y()\n",
    "        self._set_get_dummies()\n",
    "        self._transform()\n",
    "        \n",
    "        return train_test_split(self.X_trans, self.y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if self.best_estimator == None:\n",
    "            print(\"fit before predict.. \")\n",
    "        else:\n",
    "            return self.best_estimator.predict(X_test)\n",
    "    \n",
    "    \n",
    "    def get_accuracy(self,y_true, y_pred):\n",
    "        return  accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        models = self._get_grid_search_cls(self.type_ml)\n",
    "        for key,classificateur in models.items():\n",
    "            estimat = classificateur[0]\n",
    "            parameters = classificateur[1]\n",
    "            clf = GridSearchCV(estimat, param_grid = parameters, return_train_score=True, cv = 5, n_jobs=-1)\n",
    "            clf.fit(X, y)\n",
    "            if clf.best_score_ > self.best_score:\n",
    "                self.best_score = clf.best_score_\n",
    "                self.best_estimator = clf.best_estimator_\n",
    "                print(key,\":\",self.best_score,\"%\")\n",
    "                    \n",
    "   \n",
    "    def _get_grid_search_cls(self, gs_type):\n",
    "        if gs_type == \"classification\":\n",
    "            return  {\"logreg\":[LogisticRegression(),[\n",
    "                {'penalty': ['l2'],'C':[0.1,0.6,1],\n",
    "                  'multi_class':['ovr', 'multinomial'],'class_weight':['balanced', None],\n",
    "                  'solver':['lbfgs','sag','newton-cg'],'max_iter':[1000],\"random_state\": [0]\n",
    "                },\n",
    "                {'penalty': ['l1','l2'],'C':[0.1,0.6,1],\n",
    "                  'multi_class':['ovr'],'class_weight':['balanced', None],\n",
    "                  'solver':['liblinear'],'max_iter':[1000],\"random_state\": [0]\n",
    "                },]],\n",
    "              \"SVM\":[SVC(),[\n",
    "                {'C': [0.1,0.6,1,2],'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['linear'],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                },\n",
    "                {'C': [0.1,0.6,1,2], 'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['rbf'],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                },\n",
    "                {'C': [0.1,0.6,1,2], 'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['poly'], 'degree': [2,3,4,5,6,7],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                },\n",
    "                {'C': [0.1,0.6,1,2,],'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['sigmoid'],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                }]],\n",
    "              \"RanFor\":[RandomForestClassifier(),{\n",
    "                   'n_estimators': [10,20],\n",
    "                   \"criterion\": [\"gini\", \"entropy\"],\n",
    "                   \"max_depth\": [8, 10, 12, None],\n",
    "                   \"min_samples_split\": [2, 5],\n",
    "                   \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "                   \"bootstrap\": [True, False],\n",
    "                   \"class_weight\": [\"balanced\", \"balanced_subsample\", None],\n",
    "                   \"random_state\": [0]\n",
    "                   }]}\n",
    "        else:\n",
    "            return  {\"linreg\":[LinearRegression(),[\n",
    "                {'penalty': ['l2'],'C':[0.1,0.6,1],\n",
    "                  'multi_class':['ovr', 'multinomial'],'class_weight':['balanced', None],\n",
    "                  'solver':['lbfgs','sag','newton-cg'],'max_iter':[1000],\"random_state\": [0]\n",
    "                },\n",
    "                {'penalty': ['l1','l2'],'C':[0.1,0.6,1],\n",
    "                  'multi_class':['ovr'],'class_weight':['balanced', None],\n",
    "                  'solver':['liblinear'],'max_iter':[1000],\"random_state\": [0]\n",
    "                },]],\n",
    "              \"SVM\":[SVC(kernel = \"linear\"),[\n",
    "                {'C': [0.1,0.6,1,2],'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['linear'],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                },\n",
    "                {'C': [0.1,0.6,1,2], 'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['rbf'],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                },\n",
    "                {'C': [0.1,0.6,1,2], 'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['poly'], 'degree': [2,3,4,5,6,7],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                },\n",
    "                {'C': [0.1,0.6,1,2,],'class_weight':['balanced', None],\n",
    "                 'gamma': ['scale','auto'], 'kernel': ['sigmoid'],\n",
    "                 'decision_function_shape': ['ovo', 'ovr'],\"random_state\": [0]\n",
    "                }]],\n",
    "              \"RanFor\":[RandomForestRegressor(),{\n",
    "                   'n_estimators': [100,150],\n",
    "                   \"criterion\": [\"gini\", \"entropy\"],\n",
    "                   \"max_depth\": [8, 10, 12, None],\n",
    "                   \"min_samples_split\": [2, 5],\n",
    "                   \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "                   \"bootstrap\": [True, False],\n",
    "                   \"random_state\": [0]\n",
    "                   }]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg : 0.834375 %\n",
      "SVM : 0.90625 %\n",
      "RanFor : 0.909375 %\n"
     ]
    }
   ],
   "source": [
    "autoML = AutoML(\"classification\", \"Social_Network_Ads.csv\",\"Purchased\")\n",
    "X_train, X_test, y_train, y_test = autoML.pre_processing()\n",
    "autoML.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = autoML.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoML.get_accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=8, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoML.best_estimator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
