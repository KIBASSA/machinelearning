{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SpatialDropout1D,LSTM,Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/54/5f/e1b2d83b808f978f51b7ce109315154da3a3d4151aa59686002681f2e109/tensorflow-2.0.0-cp37-cp37m-win_amd64.whl (48.1MB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.6)\n",
      "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting gast==0.2.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/ae/a11b9b0c8e2410b11887881990b71f54ec39b17c4de2b5d850ef66aade8c/protobuf-3.10.0-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/a8/91d878054bdacf586ed613bec64f5c26cc0a0a2af294377c7f29469a05f4/grpcio-1.25.0-cp37-cp37m-win_amd64.whl (1.8MB)\n",
      "Collecting tensorboard<2.1.0,>=2.0.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/81/d1e7d9974ba7c886f6d133a8baae18cb8d92b2d09bcc4f46328306825de0/google_auth-1.7.0-py2.py3-none-any.whl (74kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<3.2,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/71/8f0d444e3a74e5640a3d5d967c1c6b015da9c655f35b2d308a55d907a517/pyasn1-0.4.7-py2.py3-none-any.whl (76kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
      "Building wheels for collected packages: gast, opt-einsum, termcolor, absl-py\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7546 sha256=95c9d69c3dd123ab0e67bc0ed283f08d60ba59d1006e91b3db63f912c69af118\n",
      "  Stored in directory: C:\\Users\\kibas\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for opt-einsum (setup.py): started\n",
      "  Building wheel for opt-einsum (setup.py): finished with status 'done'\n",
      "  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp37-none-any.whl size=61701 sha256=aed77f102ecc0ffda804f546e43bead8f02bdfd6b02c02eacba3190ce6a67654\n",
      "  Stored in directory: C:\\Users\\kibas\\AppData\\Local\\pip\\Cache\\wheels\\2c\\b1\\94\\43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-cp37-none-any.whl size=4835 sha256=fcfb0812f9e57193b4d88731811b45b1b9d55b9f1c751daaace80e507faf4907\n",
      "  Stored in directory: C:\\Users\\kibas\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.8.1-cp37-none-any.whl size=121171 sha256=a023bdea2a75f9d474cc4301a222e54b3006f7b56647222718a29e4c2a07fc2f\n",
      "  Stored in directory: C:\\Users\\kibas\\AppData\\Local\\pip\\Cache\\wheels\\a7\\15\\a0\\0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
      "Successfully built gast opt-einsum termcolor absl-py\n",
      "Installing collected packages: tensorflow-estimator, gast, opt-einsum, protobuf, termcolor, google-pasta, grpcio, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, absl-py, tensorboard, astor, tensorflow\n",
      "Successfully installed absl-py-0.8.1 astor-0.8.0 cachetools-3.1.1 gast-0.2.2 google-auth-1.7.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 markdown-3.1.1 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.10.0 pyasn1-0.4.7 pyasn1-modules-0.2.7 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.0.1 tensorflow-2.0.0 tensorflow-estimator-2.0.1 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.16.5)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.3.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\kibas\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
      "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kibas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#thousands allows to convert number with ',' to float\n",
    "data = pd.read_csv(\"data/critics.notes.csv\",sep=';;;; ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       film plutÃ´t dÃ©cevant! le rÃ´le confiÃ© Ã  Vi...\n",
       "14      Totalement inutile......câ€™est la seule femme...\n",
       "23      Huis clos au scÃ©nario anorexique. Sound of my...\n",
       "58      Je suis dÃ©Ã§ue, je m'attendais Ã  mieux : le ...\n",
       "63      Adaptation du roman de Kerouac horriblement lo...\n",
       "                              ...                        \n",
       "6497    Vous vous attendez Ã  voir du scream? vous ne ...\n",
       "6511    Il n'y a rien dans ce film, absolument rien!St...\n",
       "6519    ce film est un ramassis de clichÃ©.soit disant...\n",
       "6520    Sâ€™il nâ€™avait pas Ã©tÃ© signÃ© Ridley Scott...\n",
       "6523    J'aurais peut-Ãªtre Ã©vitÃ© les soupirs Ã  rÃ©...\n",
       "Name: Comment, Length: 424, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"Note\"] == 1][\"Comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Comment\"] = data[\"Comment\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 10000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split = ' ')\n",
    "tokenizer.fit_on_texts(data[\"Comment\"].values)\n",
    "X = tokenizer.texts_to_sequences(data['Comment'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1735, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 1735, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1970      \n",
      "=================================================================\n",
      "Total params: 1,536,770\n",
      "Trainable params: 1,536,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "num_classes = len(data['Note'].unique())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Note'] = pd.to_numeric(data[\"Note\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(data['Note']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "#y_train_cat = to_categorical(Y_train, num_classes)\n",
    "#y_test_cat = to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2057s - loss: 1.7522 - acc: 0.4632\n",
      "Epoch 2/20\n",
      " - 1985s - loss: 1.5672 - acc: 0.4803\n",
      "Epoch 3/20\n",
      " - 1990s - loss: 1.3249 - acc: 0.5473\n",
      "Epoch 4/20\n",
      " - 1984s - loss: 1.0957 - acc: 0.6216\n",
      "Epoch 5/20\n",
      " - 1982s - loss: 0.8703 - acc: 0.7145\n",
      "Epoch 6/20\n",
      " - 1984s - loss: 0.6762 - acc: 0.7738\n",
      "Epoch 7/20\n",
      " - 1982s - loss: 0.5428 - acc: 0.8264\n",
      "Epoch 8/20\n",
      " - 1983s - loss: 0.4315 - acc: 0.8592\n",
      "Epoch 9/20\n",
      " - 1982s - loss: 0.3385 - acc: 0.8922\n",
      "Epoch 10/20\n",
      " - 1979s - loss: 0.2714 - acc: 0.9111\n",
      "Epoch 11/20\n",
      " - 1981s - loss: 0.2139 - acc: 0.9289\n",
      "Epoch 12/20\n",
      " - 1980s - loss: 0.1758 - acc: 0.9465\n",
      "Epoch 13/20\n",
      " - 1983s - loss: 0.1463 - acc: 0.9494\n",
      "Epoch 14/20\n",
      " - 1984s - loss: 0.1207 - acc: 0.9608\n",
      "Epoch 15/20\n",
      " - 1989s - loss: 0.1065 - acc: 0.9670\n",
      "Epoch 16/20\n",
      " - 1978s - loss: 0.0966 - acc: 0.9699\n",
      "Epoch 17/20\n",
      " - 1979s - loss: 0.0844 - acc: 0.9720\n",
      "Epoch 18/20\n",
      " - 1983s - loss: 0.0706 - acc: 0.9788\n",
      "Epoch 19/20\n",
      " - 1986s - loss: 0.0591 - acc: 0.9811\n",
      "Epoch 20/20\n",
      " - 1989s - loss: 0.0626 - acc: 0.9827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4b54544128>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "model.fit(X_train, Y_train, epochs = 20, batch_size=batch_size, verbose = 2)\n",
    "#model.fit(X_train, y_train_cat, epochs = 2, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting a validation set, and measuring score and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 4.39\n",
      "acc: 0.37\n"
     ]
    }
   ],
   "source": [
    "validation_size = 100\n",
    "\n",
    "#X_validate = X_test[-validation_size:]\n",
    "#Y_validate = Y_test[-validation_size:]\n",
    "#X_test = X_test[:-validation_size]\n",
    "#Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "#score,acc = model.evaluate(X_test, y_test_cat, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   4.5  2.   5.   4.   3.   2.5  3.5  1.5  0.5]\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "#twt = [\"Un chef d'oeuvre concluant magnifiquement l'épopée entamée en 2008 avec Iron Man. Le film de l'année sans difficulté. Frissons, émotions et scènes de combats épiques : on trouve vraiment tout ce qu'on attendait de ce film et plus encore.\"]\n",
    "#twt = [\"Enfin la boucle est bouclé, ce film est une excellente conclusion à 11 ans de Marvel Cinematic Universe, il alterne entre humour et moments d’émotions. La bataille finale est épique. On aurait presque envie de lâcher une larmichette à certains moments. Sûrement le meilleur Avengers des 4 films.\"]\n",
    "#twt = [\"Il y a du bon, du très bon, mais aussi du mauvais. Dans le bon, l'humour, le scénario (en particulier la seconde heure). Dans le mauvais la première heure assez longue et lente et surtout les incohérences classiques de chez Marvel, à savoir le super fort qui prend une déculottée ou le super faible qui écrase tout sur son passage... Mais dans la globalité l'histoire se laisse bien regarder, on rit assez souvent et les effets spéciaux sont réussis.\"]\n",
    "#twt = [\"Franchement j'ai failli ne pas aller voir ce film car la durée de 3 heures, c'est beaucoup trop long pour moi. Au bout des deux heures j'en avais déjà bien marre. Bon alors oui c'est un nouvel Avengers avec toute la clique. Je ne suis pas très fan mais j'ai quand même tenu à le voir. Il y a des passages supers et d'autres franchement pénibles. Le souci c'est comme je ne suis pas friande de ce genre de films, forcément je ne peux pas mettre la note maximale.\"]\n",
    "#twt = [\"Et bien moi je me suis un peu ennuyer et pour faire court il y a trop de retournement de cerveaux et je pense qu'ils ce sont fait bouffés par leurs scénarios Thor et hulk sont devenu figurant et pas de Come back prévu il fallait faire plus simple comme infinity war qui celui là était le meilleur de tous. Comme star War il y a beaucoup de potentiel gâché. Bien à vous\"]\n",
    "#twt = [\"Trop long et scenario pas credible et frustrant de pouvoir revenir en arriere et dans le temps , ce qui annule tout interet au precedent episode. Dommage , car pour le reste ce n'etait pas trop mal avec une touche d'humour bienvenue.\"]\n",
    "#twt = [\"Déception pour le dernier film des frères Cohen. Llewyn Davis, musicien de son état, tente de vivre de la musique, sans rencontrer le succès escompté. Nous suivons ses pérégrinations dans le New-York des années 60. Sauf que le rythme du film est lent, et ce qui arrive à notre héros, ou plutôt anti-héros, n'est pas intéressant. Je me suis quelque peu ennuyé durant ce film. Cependant, la bande-son est magnifique et les airs folks chantés par Oscar Isaac sont superbement interprétés, pleins d'émotions. L'image est aussi d'une beauté rare, avec un espèce de voile blanc qui donne un esthétisme indéniable au film. Mais pour moi, cela n'occulte pas les longueurs du film ainsi que son scénario n'ayant que peu d'intérêt\"]\n",
    "twt = [\"Film très très décevant. On s'attend à un REC dans la lignée des précédents et ça n'a rien à avoir. On se retrouve avec un film gore, violent sans tension. On ne ressent pas la peur ou l'oppression du premier. Ca n'a rien à voir en fait. Ca aurait pu être un bon film s'il ne s'appelait pas RECMais là, ce comico burlesque gore tombe un peu à plat. La mariée qui se transforme en super héroine sans coeur en quelques minutes ,c'est assez gros quand même.Dans le genre Shaun of the Dead est quand même bien meilleur\"]\n",
    "\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=X.shape[1], dtype='int32', value=0)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "#print(sorted(data['Note'].unique()))\n",
    "print(data['Note'].unique())\n",
    "predicted_label = sorted(data['Note'].unique())[sentiment.argmax(axis=-1)]\n",
    "#predicted_label = data['Note'].unique()[sentiment.argmax(axis=-1)]\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5. ,  4. ,  1. ,  2. ,  1.5,  4.5,  2.5,  3. ,  3.5,  0.5])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Note'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
