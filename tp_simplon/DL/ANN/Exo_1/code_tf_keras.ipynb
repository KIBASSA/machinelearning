{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from  tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exited_Model(tf.keras.Model):\n",
    "    def __init__(self,input_dim, num_classes=1):\n",
    "        super(Exited_Model, self).__init__(name='exited_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.dense_1 = Dense(6, kernel_initializer=\"uniform\", input_dim=input_dim)\n",
    "        self.dense_2 = Dropout(0.1)\n",
    "        self.dense_3 = Dense(6, kernel_initializer=\"uniform\", activation=\"relu\")\n",
    "        self.dense_4 = Dropout(0.1)\n",
    "        self.dense_5 = Dense(1, activation=\"sigmoid\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense_4(inputs)\n",
    "        return self.dense_5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exited_pre_processor():\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_excel(\"data/Churn_Modelling.xlsx\")\n",
    "        self.df = self.df[['CreditScore', 'Geography','Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited']]\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def process(self):\n",
    "        Geography_df = pd.get_dummies(self.df[\"Geography\"], drop_first=True)\n",
    "        Gender_df = pd.get_dummies(self.df[\"Gender\"], drop_first=True)\n",
    "        df = pd.concat([self.df,Geography_df,Gender_df], axis=1)\n",
    "        self.X = df[df.columns.difference(['Exited', 'Gender','Geography'])]\n",
    "        self.y = df['Exited']\n",
    "        \n",
    "        self.X_trans = self.scaler.fit_transform(self.X)\n",
    "    \n",
    "    def get_splited_data(self):\n",
    "        return train_test_split(self.X_trans, self.y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exited_Handler:\n",
    "    def __init__(self):\n",
    "        self.pre_processor = Exited_pre_processor()\n",
    "        \n",
    "    def train(self):\n",
    "        self.pre_processor.process()\n",
    "        print(\"data processed\")\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = pre_processor.get_splited_data()\n",
    "        \n",
    "        self.predictor = Exited_Model(self.X_train.shape[1])\n",
    "        predictor.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        log_dir=\"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "        self.fit_history = predictor.fit(self.X_train, \n",
    "                                             self.y_train.to_numpy(), epochs=50, batch_size=10, \n",
    "                                             callbacks=[tensorboard_callback])\n",
    "    \n",
    "    def evaluate(self):\n",
    "        test_loss, test_accuracy = self.predictor.evaluate(self.X_test,self.y_test)\n",
    "        print(\"test_loss : \", test_loss)\n",
    "        print(\"test_accuracy : \", test_accuracy)\n",
    "    \n",
    "    def plot(self):\n",
    "        plt.plot(self.fit_history.history[\"accuracy\"])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = Exited_Handler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processed\n",
      "Train on 8000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 94us/sample - loss: 0.4377 - accuracy: 0.8052\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4355 - accuracy: 0.8052\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4407 - accuracy: 0.8054\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4374 - accuracy: 0.8074\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4381 - accuracy: 0.8059\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4370 - accuracy: 0.8070\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4392 - accuracy: 0.8045\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4404 - accuracy: 0.8020\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4375 - accuracy: 0.8065\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4377 - accuracy: 0.8062\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4375 - accuracy: 0.8060\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4355 - accuracy: 0.8080\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4363 - accuracy: 0.8052\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4399 - accuracy: 0.8030s - loss: 0.4401 - accuracy: 0.\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4410 - accuracy: 0.8050\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.4366 - accuracy: 0.8070\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 1s 68us/sample - loss: 0.4395 - accuracy: 0.8035\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4374 - accuracy: 0.8049\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4402 - accuracy: 0.8029\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4360 - accuracy: 0.8087\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4406 - accuracy: 0.8060\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.4383 - accuracy: 0.8045\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 1s 83us/sample - loss: 0.4364 - accuracy: 0.8064\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4363 - accuracy: 0.8051\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4367 - accuracy: 0.8048\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4358 - accuracy: 0.8046\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 1s 85us/sample - loss: 0.4384 - accuracy: 0.8048s - loss: 0.4429 - accuracy - ETA: 0s - loss: 0.4364 - accuracy\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.4361 - accuracy: 0.8079\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 1s 81us/sample - loss: 0.4387 - accuracy: 0.8050\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.4381 - accuracy: 0.8085\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4371 - accuracy: 0.8070\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4367 - accuracy: 0.8077\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 1s 76us/sample - loss: 0.4379 - accuracy: 0.8052\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 1s 80us/sample - loss: 0.4384 - accuracy: 0.8049\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 1s 75us/sample - loss: 0.4379 - accuracy: 0.8044\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 1s 77us/sample - loss: 0.4396 - accuracy: 0.8061\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.4405 - accuracy: 0.8079\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.4374 - accuracy: 0.8048\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4384 - accuracy: 0.8066\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 1s 69us/sample - loss: 0.4373 - accuracy: 0.8062\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4373 - accuracy: 0.8045s - loss: 0.4423 - accuracy: 0.79 - ETA: 0s - loss: 0.4425 - accuracy: \n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 1s 72us/sample - loss: 0.4362 - accuracy: 0.8066\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 1s 73us/sample - loss: 0.4401 - accuracy: 0.8046\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4382 - accuracy: 0.8050\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 1s 70us/sample - loss: 0.4388 - accuracy: 0.8059\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4375 - accuracy: 0.8054\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.4371 - accuracy: 0.8046\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 1s 71us/sample - loss: 0.4370 - accuracy: 0.8037\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 1s 74us/sample - loss: 0.4374 - accuracy: 0.8066\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 1s 79us/sample - loss: 0.4396 - accuracy: 0.8049\n"
     ]
    }
   ],
   "source": [
    "handler.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
